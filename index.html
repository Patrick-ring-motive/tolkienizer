<html>
  <head>
    <style>
      html {
        background-image: url("bak.jpeg");
        background-size: cover;
      }

      h1,
      h3 {
        font-family: sans-serif;
      }
      button,
      loading,
      h1,
      h3,
      pre {
        border-radius: 1vmax;
        background-color: rgba(118, 207, 138, 0.8);
        max-width: 100vw;
      }
      button,
      loading,
      code {
        white-space: pre-wrap;
        word-break: normal !important;
        font-size: 4vmin;
      }
      buttons {
        width: 100%;
      }
      button {
        color: #003200 !important;
        margin: 1vmax;
      }
      pre {
        padding: 1vmax;
      }
      log {
        color: red;
      }
    </style>
    <script>
      //utilities to simplify stream conversion
      ReadableStream.prototype.gunzip = function gunzip() {
        return this.pipeThrough(new DecompressionStream("gzip"));
      };
      ReadableStream.prototype.text = async function text() {
        return await new Response(this).text();
      };

      //polyfill for safari streams
      ReadableStream.prototype[Symbol.asyncIterator] ??=
        async function* asyncIterator() {
          const reader = this?.getReader?.();
          try {
            let chunk = await reader.read();
            while (chunk?.done === false) {
              yield chunk?.value;
              chunk = await reader?.read?.();
            }
          } finally {
            reader?.releaseLock?.();
          }
        };
      window.log = (e) => {
        console.log(e);
        (document.querySelector("log") ?? {}).innerHTML += ("<br>" + (e.message??e));
      };
      window.addEventListener("error", function (e) {
        log(e?.message);
        [...arguments].forEach(x=>{
          log("window error "+(x?.message??x));
        });
      });
    </script>
    <title>Tolkienizer</title>
  </head>
  <body>
    <center>
      <h1>Tolkienizer</h1>
      <br />
      <h3>
        This little project is my attempt at creating a language trimodel from
        scratch and have it run entirely clientside. It's a simple trigram
        trimodel trained on the 3 LotR books and The Hobbit. It has a bunch of
        small optimizations to seem more coherent. It's no Chatgpt but it is
        fun.⠀<a href="https://github.com/Patrick-ring-motive/tolkienizer"
          >Here's the code or whatever.</a
        >
      </h3>
    </center>
    <buttons></buttons>
    <loading>loading...</loading>
    <pre><code></code></pre>
    <script>
      (async () => {
        try {
          let trimodel;
          let bimodel;
          //download the trimodel. Its a gzipped json dictionary of trigrams.
          await Promise.all([
            (async () => {
              const res = await fetch("trimodel.json.txt.gz");
              trimodel = JSON.parse(await res.body.gunzip().text());
            })(),
            (async () => {
              const res = await fetch("bimodel.json.txt.gz");
              bimodel = JSON.parse(await res.body.gunzip().text());
            })(),
          ]);

          document.querySelector("loading")?.remove?.();
          //longest common subsequence. Used to find the closest matching trigram if no exact match is found.
          const lcs = function lcs(seq1, seq2) {
            "use strict";
            let arr1 = [...(seq1 ?? [])];
            let arr2 = [...(seq2 ?? [])];
            if (arr2.length > arr1.length) {
              [arr1, arr2] = [arr2, arr1];
            }
            const dp = Array(arr1.length + 1)
              .fill(0)
              .map(() => Array(arr2.length + 1).fill(0));
            const dp_length = dp.length;
            for (let i = 1; i !== dp_length; i++) {
              const dpi_length = dp[i].length;
              for (let x = 1; x !== dpi_length; x++) {
                if (arr1[i - 1] === arr2[x - 1]) {
                  dp[i][x] = dp[i - 1][x - 1] + 1;
                } else {
                  dp[i][x] = Math.max(dp[i][x - 1], dp[i - 1][x]);
                }
              }
            }
            return dp[arr1.length][arr2.length];
          };

          const stringify = (x) => {
            try {
              return JSON.parse(x);
            } catch {
              return String(x);
            }
          };

          //Count the number of of possible trigrams that follow a given trigram
          const followCount = (model, key) => {
            if (!model[key]) return 0;
            return Object.keys(model[key]).length;
          };

          function getContextBoost(tokens, key) {
            const context = stringify(tokens.slice(-20));
            return lcs(context, key) / context.length / 20;
          }

          const actors = 'Aragorn|Frodo|Gandalf|Legolas|Gimli|Boromir|Samwise|Merry|Pippin|Faramir|Denethor|Elrond|Galadriel|Saruman'.toLowerCase().split("|");
          const activeActors = {};

          function getActorBoost(model,key){
            if (!model[key]) return 0;
          let score=0;
            const smk = stringify(model[key]).toLowerCase();
        for(const actor in activeActors){
            score+=(0.2 * (lcs(smk, actor) *
            Math.min(key.length, keywords.length)) /
          Math.max(key.length, keywords.length));
        }
            return score;
          };

          //Get the next token in the sequence. This is the core of the model.
          function getNextToken(keywords, trimodel, bimodel, tokens = []) {
            const strtok = stringify(tokens);
            let model = trimodel;
            let maxMatch = 0;
            let keyMatch = keywords;
            let matches = trimodel[keywords];
            // 10% chance to do fuzzy match search even if exact match is found.
            if (!matches) {
              matches = bimodel[keywords.split(" ").pop()];
              if (!matches) {
                for (const key in trimodel) {
                  // lcs finds common sequences.
                  // min length/max length punishes differences in length
                  // strtok.split(key).length punishes repeated sequences
                  const keylcs =
                    (lcs(key, keywords) *
                      Math.min(key.length, keywords.length)) /
                    (Math.max(key.length, keywords.length) *
                      strtok.split(key).length);
                  if (keylcs > maxMatch) {
                    maxMatch = keylcs;
                    keyMatch = key;
                  }
                }
                matches = trimodel[keyMatch];
              } else {
                model = bimodel;
              }
            }
            maxMatch = 0;
            for (const key in matches) {
              //followCount boosts trigrams that have more possible followups
              //followCount is a hueristic inspired by Kneser–Ney smoothing but much simpler
              if (
                (matches[key] +
                  getActorBoost(model,key) +
                  getContextBoost(tokens, key) +
                  followCount(model, key) * 0.01) /
                  strtok.split(key).length >
                maxMatch
              ) {
                maxMatch = matches[key];
                keyMatch = key;
              }
            }
            keyMatch = stringify(keyMatch);
            const lk = keyMatch.toLowerCase();
            for(const actor of actors){
              if(lk.includes(actor)){
                activeActors[actor] = 20;
              }
            }
            for(const actor in activeActors){
              activeActors[actor]--;
              if(activeActors[actor]<=0){
                delete activeActors[actor];
              }
            }
            if(/[A-Z]/.test(keyMatch)&&!/\?|\.|\!/.test(keywords) ){
              activeActors[keyMatch]=20;
            }
            return keyMatch;
          }

          const join = (x, y = "") => {
            try {
              return x.join(y);
            } catch {
              return String(y);
            }
          };

          const nextTime =
            globalThis.requestIdleCallback ??
            globalThis.requestAnimationFrame ??
            ((x) => setTimeout(x, 0));

          const nextIdle = () => new Promise((resolve) => nextTime(resolve));

          function generateStream(prompt, trimodel, bimodel, context = []) {
            return new ReadableStream({
              async start(controller) {
                try {
                  const tokens = context;
                  if (!prompt) {
                    prompt = context[context.length - 1];
                  }
                  if (!prompt) {
                    prompt = getNextToken(
                      crypto.randomUUID(),
                      trimodel,
                      bimodel,
                      tokens,
                    );
                  }
                  const out = [];
                  context.push(prompt);
                  while (join(out).split(/[\.\?\!]/).length < 10) {
                    await nextIdle();
                    const nextToken = getNextToken(
                      `${tokens[tokens.length - 2]} ${tokens[tokens.length - 1]}`,
                      trimodel,
                      bimodel,
                      tokens,
                    );
                    tokens.push(nextToken);
                    out.push(nextToken);
                    controller.enqueue(nextToken);
                  }
                  controller.close();
                } catch (e) {
                  log(e.message);
                }
              },
            });
          }

          const cap = (txt) => {
            txt = txt.trim();
            return (txt[0]?.toUpperCase?.() || "") + txt.slice(1);
          };
          function appendText(text) {
            document.querySelector("code").innerHTML = cap(
              document.querySelector("code").innerHTML + " " + text,
            )
              .replaceAll("_", " ")
              .replace(/\? [a-z]/g, (x) => x.toUpperCase())
              .replace(/\. [a-z]/g, (x) => x.toUpperCase())
              .replace(/\! [a-z]/g, (x) => x.toUpperCase());
          }
          let context = JSON.parse(localStorage.getItem("context") || "[]");
          appendText(join(context, " "));
          const buttons = document.querySelector("buttons");
          const gen = document.createElement("button");
          gen.innerHTML = "Generate";
          gen.onclick = async () => {
            await nextIdle();
            let prompt;
            const stream = generateStream(prompt, trimodel, bimodel, context);

            for await (const chunk of stream) {
              localStorage.setItem("context", JSON.stringify(context));
              appendText(chunk);
            }
          };
          buttons.appendChild(gen);
          const clear = document.createElement("button");
          clear.innerHTML = "Clear";
          clear.onclick = () => {
            localStorage.setItem("context", "[]");
            context = [];
            document.querySelector("code").innerHTML = "";
          };
          buttons.appendChild(clear);
        } catch (e) {
          log(e.message);
        }
      })();
    </script>
    <log></log>
  </body>
</html>
